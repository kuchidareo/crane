datasets = {
    "pamap": [
        "lie", "sit", "stand", "walk", "run", "cycle", "Nordic walk", "iron", 
        "vacuum clean", "rope jump", "ascend stairs", "descend stairs"
    ],
    # "extrasensory": [
    #     "indoors", "LOC_home", "SITTING", "PHONE_ON_TABLE", "LYING_DOWN", "SLEEPING",
    #     "AT_SCHOOL", "COMPUTER_WORK", "standing", "TALKING", "LOC_main_workplace",
    #     "WITH_FRIENDS", "PHONE_IN_POCKET", "FIX_walking", "SURFING_THE_INTERNET",
    #     "EATING", "PHONE_IN_HAND", "WATCHING_TV", "outside", "PHONE_IN_BAG",
    #     "exercise", "DRIVE_-_I_M_THE_DRIVER", "WITH_CO-WORKERS", "IN_CLASS",
    #     "IN_A_CAR", "IN_A_MEETING", "BICYCLING", "COOKING", "LAB_WORK", "CLEANING",
    #     "GROOMING", "TOILET", "DRIVE_-_I_M_A_PASSENGER", "DRESSING", "FIX_restaurant",
    #     "BATHING_-_SHOWER", "SHOPPING", "ON_A_BUS", "AT_A_PARTY", "DRINKING__ALCOHOL_",
    #     "WASHING_DISHES", "AT_THE_GYM", "FIX_running", "STROLLING", "STAIRS_-_GOING_UP",
    #     "STAIRS_-_GOING_DOWN", "SINGING", "LOC_beach", "DOING_LAUNDRY", "AT_A_BAR",
    #     "ELEVATOR"
    # ],
    "extrasensory_simple": [
        "indoors", "home", "sitting", "phone on table", "lying down", "sleeping", "at school",
        "computer work", "standing", "talking", "workplace", "with friends", "phone in pocket", 
        "walking", "surfing internet", "eating", "phone in hand", "watching tv", "outside", 
        "phone in bag", "exercise", "driving driver", "with coworkers", "in class", "in car", 
        "meeting", "bicycling", "cooking", "lab work", "cleaning", "grooming", "toilet", "driving passenger", 
        "dressing", "restaurant", "shower", "shopping", "on bus", "at party", "drinking", "washing dishes", 
        "gym", "running", "strolling", "stairs up", "stairs down", "singing", "beach", "laundry", "bar", 
        "elevator"
    ],
    "domino": [
        "brushing teeth", "cycling", "elevator down", "elevator up", "lying", "moving by car",
        "running", "sitting", "sitting on transport", "stairs down", "stairs up", "standing",
        "standing on transport", "walking"
    ],
    "dsads": [
        "sitting", "standing", "lying on back", "lying on right side", "ascending stairs",
        "descending stairs", "standing in an elevator still", "moving around", 
        "walking in parking lot", "walking on treadmill with a speed of 4 km/h in a flat position",
        "walking on treadmill with a speed of 4 km/h in a 15 degree inclined position", 
        "running on treadmill with a speed of 8 km/h", "exercising on stepper", 
        "exercising on cross trainer", "cycling on exercise bike in horizontal position",
        "cycling on exercise bike in vertical position", "rowing", "jumping", "playing basketball"
    ],
    "ku_har": [
        "stand", "sit", "talk sit", "talk stand", "stand sit", "lay", "lay stand", "pick",
        "jump", "push up", "sit up", "walk", "walk backward", "walk circle", "run", 
        "stair up", "stair down", "table tennis"
    ],
    "coco_caption": [
        'A woman leads a horse on a city sidewalk.',
        'A man who is on a small boat in the water.',
        'A woman in a black coat holds an umbrella in the rain.',
        'A hospital bed is in the upright position while a laptop sits open.',
        'Several people are at the beach flying kites.',
        'A male tennis player hits the ball in a match.',
        'A bathroom showing the top of a toilet tank, sink and mirror.',
        'A person entering a crosswalk along a city street.',
        'Group of pigeons standing together on the ground. ',
        'A blue tow truck carrying a boat. ',
        'The man is on the tennis court playing a game.',
        'The vegetables are sitting on the kitchen counter.  ',
        'Two red busses on street next to buildings.',
        'A dinner table with several different dishes on it.',
        'Surfers waiting for the right wave to ride.',
        'A person holding their hand up to a horse.',
        'The horses are all behind the barbwire fencing.',
        'A young boy playing with a game remote.',
        'Several different types of doughnuts on a plate.',
        'A United Airlines plane begins its descent onto the runway.',
        'an image of a bus with a group of kids about to park',
        'A green toilet sits on top of brown tile in a bathroom area.',
        'Rows of suitcases at the luggage claim of an airport.',
        'A woman in yellow and white dress playing a game of tennis.',
        'Baseball catcher in black and yellow uniform waiting for the ball.',
        'a small boat in a narrow body of water ',
        'A parking meter on the street is painted with multiple colors.',
        'A clock tower above an empty city street.',
        'A police car sitting on a street next to a  truck.',
        'Man dressed in Native American clothes protecting musical instruments from the rain with an umbrella.',
        'A street sign embedded in a brick wall',
        'A batter and catcher on a baseball field.',
        'A passenger bus with cars and trucks lined up behind.',
        'People looking at motorcycles parked in a row.',
        'A young woman with a smile on her face rides her bicycle down the street past some parked cars.',
        'A young man tossing a white frisbee across a field.',
        'Person sitting on the snow with their snowboard strapped on.',
        'A silver refrigerator stands in a sparse kitchen.',
        'Several men in short shorts playing doubles tennis.',
        'A person sailing a boat with a dog',
        'A man is flying a kite by the beach.',
        'A man on snow skis going over some snow.',
        'Rows of surfboards in covers on a brick sidewalk.',
        'a man attempting to hit a ball with a tennis rracket',
        'There is a black and white photo of a woman laying in bed',
        'Four zebras are standing in a grassy field.',
        'A kitchen with wooden cabinets, microwave, and refrigerator.',
        'A baseball player swinging a bat over a base.',
        'A guy wearing a green shirt playing WII while others watch.',
        'A traffic light reads green on a city street.'
    ],
    "crane_caption": [
        "The user is likely preparing food or setting up for a meal, possibly involving bread.",
        "The user is in the kitchen, preparing a meal or snack, involving retrieving bread from the fridge and possibly organizing or cleaning up with the dishwasher.",
        "The user is preparing or setting up food, likely in a kitchen, involving movement between spaces and handling food items.",
        "The user is preparing a meal or snack involving cheese and salami while organizing or cleaning the kitchen, including managing dishes in the dishwasher.",
        "The user is in a kitchen, likely preparing a drink or snack by retrieving items from the fridge and handling a glass.",
        "The user is moving between rooms, likely carrying a drink, and interacting with doors.",
        "The user is likely preparing a meal or snack, possibly involving bread, in a kitchen or dining area.",
        "The user is likely preparing or handling food, possibly walking to a table or counter with bread.",
        "The user is preparing a meal or snack in the kitchen, involving both food and drink preparation, while also organizing or cleaning the space.",
        "The user is preparing a meal in the kitchen, likely involving bread as a key ingredient.",
        "The user is likely relaxing while engaging in a light activity such as using a device or reading.",
        "The user is tidying up and organizing in a kitchen, likely after food preparation or a meal.",
        "The user is preparing and serving a meal in a kitchen or dining area, while also tidying up the space.",
        "The user is likely in a kitchen, possibly preparing a meal or organizing items in the fridge.",
        "The user is preparing a meal or snack in the kitchen, involving salami and organizing kitchen items.",
        "The user is preparing and serving a meal or snack, likely involving cheese and salami, and is now sitting down to eat.",
        "The user is likely relaxing at home, transitioning between sitting and lying down, after interacting with an object like a book or remote control.",
        "The user is relaxing in a living room, having adjusted the environment and settled into a lazy chair with a drink.",
        "The user is likely preparing or handling food, possibly making a meal or snack, in a kitchen or dining area.",
        "The user is having a meal, likely preparing or eating a sandwich and drinking a beverage, while seated.",
        "The user is preparing a snack or meal, possibly involving a drink, while sitting.",
        "The user is having a meal, likely preparing and eating a sandwich with bread and salami, and drinking from a cup while seated.",
        "The user is preparing food or setting up for a meal, likely moving between a kitchen and dining area.",
        "The user is preparing and drinking a beverage, likely coffee or tea, in a kitchen or dining area.",
        "The user is engaged in post-meal kitchen cleanup, organizing dishes and closing the dishwasher.",
        "The user is preparing food and tidying up in the kitchen.",
        "The user is preparing or serving food and/or a beverage, likely in a kitchen or dining area.",
        "The user is engaged in a structured cleaning routine, moving between areas to clean surfaces and interact with doors and switches, likely in a home or office environment.",
        "The user is transitioning from moving around to lying down, possibly preparing to rest or relax, while reaching for an object.",
        "The user is likely preparing or consuming food involving bread."
    ]
}

import spacy
import numpy as np
import math
from collections import Counter
from scipy.spatial.distance import euclidean
from nltk import word_tokenize
from nltk.probability import FreqDist
from nltk.util import ngrams
from sentence_transformers import SentenceTransformer

# Load NLP models
nlp = spacy.load("en_core_web_sm")
model = SentenceTransformer("all-MiniLM-L6-v2")

def word_count(texts):
    num_words = []
    for text in texts:
        words = text.split()
        num_words.append(len(words))
    return np.mean(num_words) if num_words else 0
# 1. Lexical Diversity & Richness

# Type-Token Ratio (TTR)
def type_token_ratio(texts):
    num_unique_words = []
    for text in texts:
        words = text.split()
        unique_words = set(words)
        num_unique_words.append(len(unique_words) / len(words))
    return np.mean(num_unique_words) if num_unique_words else 0

# Measure of Textual Lexical Diversity (MTLD)
def mtld(texts, threshold=0.72):
    mtld_value = []
    for text in texts:
        words = [word.lower() for word in text.split()]
        factors = 0
        total_words = len(words)
        if total_words == 0:
            return 0
        segment = []
        for word in words:
            segment.append(word)
            ttr = len(set(segment)) / len(segment)
            if ttr < threshold:
                factors += 1
                segment = []
        if segment:
            factors += 1
        mtld_value.append(total_words / factors)
    return np.mean(mtld_value) if mtld_value else 0

# HDD (Hypergeometric Distribution Diversity)
def hdd(texts, sample_size=42):
    hdds = []
    for text in texts:
        words = [word.lower() for word in text.split()]
        freq_dist = FreqDist(words)
        total_words = sum(freq_dist.values())
        hdd = 0
        for word in freq_dist.keys():
            prob = freq_dist[word] / total_words
            hdd += (1 - prob) ** sample_size
        hdds.append(1 - hdd)
    return np.mean(hdds) if hdds else 0

# 2. Syntactic Complexity

# Mean Dependency Length (MDL)
def mean_dependency_length(texts):
    lengths = []
    for text in texts:
        doc = nlp(text)
        lengths.extend([abs(token.i - token.head.i) for token in doc if token.dep_ != "ROOT"])
    return np.mean(lengths) if lengths else 0

# Parse Tree Depth
def parse_tree_depth(texts):
    depths = []
    for text in texts:
        doc = nlp(text)
        depths.append(max([token.i - token.head.i for token in doc if token.dep_ != "ROOT"], default=0))
    return np.mean(depths) if depths else 0

# Number of Clauses
def clause_count(texts):
    clause_tags = {"ccomp", "xcomp", "advcl", "acl", "relcl"}
    counts = []
    for text in texts:
        doc = nlp(text)
        counts.append(sum(1 for token in doc if token.dep_ in clause_tags))
    return np.mean(counts) if counts else 0

# 3. Information Density

# Entropy of Words
def word_entropy(texts):
    entropy_list = []
    for text in texts:
        word_counts = Counter()
        words = text.lower().split()
        word_counts.update(words)
        total_words = len(words)
        probs = [count / total_words for count in word_counts.values()]
        entropy = -sum(p * math.log2(p) for p in probs if p > 0)
        entropy_list.append(entropy)
    return np.mean(entropy_list) if entropy_list else 0

# POS Diversity
def pos_diversity(texts):
    pos_counts = Counter()
    total_words = 0
    for text in texts:
        doc = nlp(text)
        pos_counts.update(token.pos_ for token in doc)
        total_words += len(doc)
    return len(pos_counts) / total_words if total_words else 0

# Named Entity Recognition (NER) Count
def ner_count(texts):
    ner_total = sum(len(nlp(text).ents) for text in texts)
    return ner_total / len(texts) if texts else 0

# 4. Semantic Similarity & Embedding-Based Measures

# Word Moverâ€™s Distance (WMD) - Requires Gensim (Not implemented here for simplicity)
# BERT Embedding Norm (Sentence Richness)
def semantic_richness(texts):
    embeddings = model.encode(texts)
    norms = [np.linalg.norm(emb) for emb in embeddings]
    return np.mean(norms) if norms else 0

# Function to calculate the total distance between embeddings
def total_embedding_distance(texts):
    embeddings = model.encode(texts)  # Get embeddings for each label
    total_distance = 0
    num_embeddings = len(embeddings)

    # Calculate the pairwise distance between embeddings
    for i in range(num_embeddings):
        for j in range(i + 1, num_embeddings):
            distance = np.linalg.norm(embeddings[i] - embeddings[j])
            total_distance += distance

    return total_distance

# Function to count Named Entities (NE)
def count_named_entities(texts):
    ner_count = 0
    for text in texts:
        doc = nlp(text)
        ner_count += len(doc.ents)  # Count named entities in each label
    return ner_count

# Compute and store results for each dataset
results = {}
for dataset_name, labels in datasets.items():
    results[dataset_name] = {
        "Word Count": word_count(labels),
        "Lexical Diversity (TTR)": type_token_ratio(labels),
        "Lexical Richness (MTLD)": mtld(labels),
        "Lexical Richness (HDD)": hdd(labels),
        "Syntactic Complexity (MDL)": mean_dependency_length(labels),
        "Syntactic Complexity (Tree Depth)": parse_tree_depth(labels),
        "Syntactic Complexity (Clause Count)": clause_count(labels),
        "Information Density (Entropy)": word_entropy(labels),
        "Information Density (POS Diversity)": pos_diversity(labels),
        "Information Density (NER Count)": ner_count(labels),
        "Semantic Richness (BERT Norm)": semantic_richness(labels),
        "Total Embedding Distance": total_embedding_distance(labels),
        "Named Entity Count": count_named_entities(labels)
    }

# Print results in the desired format
for metric in results["pamap"].keys():  # Iterate over the keys (metrics)
    print(f"\n{metric}:")
    for dataset, metrics in results.items():
        print(f"  {dataset}: {metrics[metric]:.4f}")